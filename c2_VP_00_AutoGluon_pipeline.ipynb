{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e34784-c18d-49ea-ac30-1fd4d20ba77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd9ca8-7825-4970-a683-51867af80be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for this notebook to run\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "\n",
    "from google.cloud import aiplatform as vertex\n",
    "\n",
    "import kfp\n",
    "from kfp.v2 import dsl, compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a579aaa-99d4-482e-9179-3a8ab6e610ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters\n",
    "PROJECT_ID = \"your-project-id\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = f\"bkt-{PROJECT_ID}-vpipelines\"\n",
    "BUCKET_PATH = f\"gs://{BUCKET_NAME}\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_PATH}/pipeline_root\"\n",
    "PIPELINE_DATA = f\"{BUCKET_PATH}/data\"\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a88355-313c-40f3-ac7b-ddaedfe39017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download BigQuery data and convert to CSV\n",
    "@dsl.component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"db-dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"component_create_dataset.yaml\"\n",
    ")\n",
    "def get_dataframe(\n",
    "    bq_table: str,\n",
    "    output_data_path: dsl.OutputPath(\"Dataset\")\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    project_number = os.environ[\"CLOUD_ML_PROJECT_ID\"]\n",
    "    bqclient = bigquery.Client(project=project_number)\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe = dataframe.sample(frac=1, random_state=2, replace=True)\n",
    "    \n",
    "    dataframe.to_csv(output_data_path)\n",
    "    output_data_path = output_data_path + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c3f6b-0b88-41d2-a8b6-04bdd62941fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autogluon container\n",
    "@dsl.component(\n",
    "    packages_to_install=[\"autogluon\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"component_autogluon_model.yaml\"\n",
    ")\n",
    "def autogluon_train(\n",
    "    dataset: dsl.Input[dsl.Dataset]\n",
    "    , model: dsl.Output[dsl.Model]\n",
    "):\n",
    "    \n",
    "    # build the default autogluon model\n",
    "    from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "    \n",
    "    label = 'label'\n",
    "    train_data = TabularDataset(dataset.path)\n",
    "    predictor = TabularPredictor(label=label, path=model.path).fit(train_data)\n",
    "    model.uri = model.uri  + \"/predictor.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0143a-b5ac-48d4-872e-41a08c3e5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# define the pipeline\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa215d-b36b-4053-9d44-dc73f2697b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a pipeline\n",
    "@dsl.pipeline(name=\"autogluon-testing\", description=\"my pipeline description\")\n",
    "\n",
    "# specify all the inputs the pipeline needs to run\n",
    "def my_pipeline(\n",
    "    bq_table: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project_id: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "        \n",
    "    # specify the nodes in the pipeline\n",
    "    dataset_task = get_dataframe(bq_table)\n",
    "\n",
    "    model_task = autogluon_train(dataset_task.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd2c6b-62df-4772-aebc-3704c3a4c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#\n",
    "# compile and run the pipeline\n",
    "#\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e635bec-dd61-4f87-b3d2-e70bccd62a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the pipeline\n",
    "my_package_path = 'my_vertex_pipeline_specification_file.json'\n",
    "compiler.Compiler().compile(pipeline_func=my_pipeline, package_path=my_package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884cf1b-afcb-46af-9f1a-7f21b47c54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime parameters to pass to pipeline\n",
    "pipeline_params = {\"bq_table\": \"yourproject.yourds.yourtable\"}\n",
    "\n",
    "# run the pipeline\n",
    "vertex.init(project=PROJECT_ID)\n",
    "\n",
    "job = vertex.PipelineJob(\n",
    "    display_name = \"my-pipeline-job-name\",\n",
    "    template_path = my_package_path,\n",
    "    pipeline_root = PIPELINE_ROOT,\n",
    "    parameter_values = pipeline_params,\n",
    "    enable_caching = True\n",
    ")\n",
    "\n",
    "job.submit(service_account=\"sa-vertex-pipelines@ap-alto-ml-1000.iam.gserviceaccount.com\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
